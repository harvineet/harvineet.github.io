---
---

@string{aps = {American Physical Society,}}

@misc{singh2022leverage,
  abbr={preprint},
  author={Harvineet Singh and Christopher Musco and Rumi Chunara},
  title={Active Linear Regression in the Online Setting via Leverage Score Sampling},
  pdf={https://drive.google.com/file/d/1g26JqEhS7_Mc8gTIhVhfh-qrNBtieG2z/view?usp=share_link},
  year=2022,
}

@inproceedings{zhang2022why,
  abbr={preprint},
  title={Why did the Model Fail?: Attributing Model Performance Changes to Distribution Shifts},
  author={Haoran Zhang and Harvineet Singh and Marzyeh Ghassemi and Shalmali Joshi},
  booktitle={NeurIPS 2022 Workshop on Distribution Shifts: Connecting Methods and Applications},
  year={2022},
  html={https://openreview.net/forum?id=2RbyKK-l9x}
}

@inproceedings{lobo2022data,
  abbr={UAI},
  bibtex_show={true},
  title={Data Poisoning Attacks on Off-Policy Policy Evaluation Methods},
  author={Elita Lobo and Harvineet Singh and Marek Petrik and Cynthia Rudin and Himabindu Lakkaraju},
  booktitle={The 38th Conference on Uncertainty in Artificial Intelligence},
  year={2022},
  html={https://openreview.net/forum?id=BgbgH_Ls5lc}
}

@article{singh2022eicu,
  abbr={PLOS Journal},
  bibtex_show={true},
  doi={10.1371/journal.pdig.0000023},
  author={Singh, Harvineet AND Mhasawade, Vishwali AND Chunara, Rumi},
  journal={PLOS Digital Health},
  publisher={Public Library of Science},
  title={Generalizability challenges of mortality risk prediction models: A retrospective analysis on a multi-center database},
  year={2022},
  html={https://doi.org/10.1371/journal.pdig.0000023},
  abstract={Modern predictive models require large amounts of data for training and evaluation, absence of which may result in models that are specific to certain locations, populations in them and clinical practices. Yet, best practices for clinical risk prediction models have not yet considered such challenges to generalizability. Here we ask whether population- and group-level performance of mortality prediction models vary significantly when applied to hospitals or geographies different from the ones in which they are developed. Further, what characteristics of the datasets explain the performance variation? In this multi-center cross-sectional study, we analyzed electronic health records from 179 hospitals across the US with 70,126 hospitalizations from 2014 to 2015. Generalization gap, defined as difference between model performance metrics across hospitals, is computed for area under the receiver operating characteristic curve (AUC) and calibration slope. To assess model performance by the race variable, we report differences in false negative rates across groups. Data were also analyzed using a causal discovery algorithm “Fast Causal Inference” that infers paths of causal influence while identifying potential influences associated with unmeasured variables. When transferring models across hospitals, AUC at the test hospital ranged from 0.777 to 0.832 (1st-3rd quartile or IQR; median 0.801); calibration slope from 0.725 to 0.983 (IQR; median 0.853); and disparity in false negative rates from 0.046 to 0.168 (IQR; median 0.092). Distribution of all variable types (demography, vitals, and labs) differed significantly across hospitals and regions. The race variable also mediated differences in the relationship between clinical variables and mortality, by hospital/region. In conclusion, group-level performance should be assessed during generalizability checks to identify potential harms to the groups. Moreover, for developing methods to improve model performance in new environments, a better understanding and documentation of provenance of data and health processes are needed to identify and mitigate sources of variation.},
  selected={true}
}

@article{singh2021policy,
  abbr={AIES},
  bibtex_show={true},
  author={Harvineet Singh and Shalmali Joshi and Finale Doshi{-}Velez and Himabindu Lakkaraju},
  title={Towards Robust Off-Policy Evaluation via Human Inputs},
  journal={AAAI/ACM Conference on AI, Ethics, and Society},
  year={2022},
  html={https://arxiv.org/abs/2103.15933},
  selected={true}
}

@inproceedings{singh2021covariate,
  abbr={FAccT},
  bibtex_show={true},
  author={Singh, Harvineet and Singh, Rina and Mhasawade, Vishwali and Chunara, Rumi},
  title={Fairness Violations and Mitigation under Covariate Shift},
  year={2021},
  isbn={9781450383097},
  html={https://doi.org/10.1145/3442188.3445865},
  doi={10.1145/3442188.3445865},
  abstract={We study the problem of learning fair prediction models for unseen test sets distributed differently from the train set. Stability against changes in data distribution is an important mandate for responsible deployment of models. The domain adaptation literature addresses this concern, albeit with the notion of stability limited to that of prediction accuracy. We identify sufficient conditions under which stable models, both in terms of prediction accuracy and fairness, can be learned. Using the causal graph describing the data and the anticipated shifts, we specify an approach based on feature selection that exploits conditional independencies in the data to estimate accuracy and fairness metrics for the test set. We show that for specific fairness definitions, the resulting model satisfies a form of worst-case optimality. In context of a healthcare task, we illustrate the advantages of the approach in making more equitable decisions.},
  booktitle={Proceedings of the ACM Conference on Fairness, Accountability, and Transparency},
  keywords={algorithmic fairness, causal inference, domain adaptation, covariate shift},
  location={Virtual Event, Canada},
  series={FAccT},
  selected={true}
}

@inproceedings{hiranandani2019cascading,
  abbr={UAI},
  bibtex_show={true},
  title={Cascading Linear Submodular Bandits: Accounting for Position Bias and Diversity in Online Learning to Rank},
  author={Hiranandani, Gaurush and Singh, Harvineet and Gupta, Prakhar and Kveton, Branislav and Wen, Zheng and Burhanuddin, Iftikhar Ahamath},
  booktitle={UAI},
  year={2019},
  html={https://proceedings.mlr.press/v115/hiranandani20a.html},
  selected={true}
}

@inproceedings{sinha2018time,
  abbr={WSDM},
  bibtex_show={true},
  author={Sinha, Moumita and Vinay, Vishwa and Singh, Harvineet},
  title={Modeling Time to Open of Emails with a Latent State for User Engagement Level},
  booktitle={Proceedings of the Eleventh ACM International Conference on Web Search and Data Mining},
  series={WSDM '18},
  year={2018},
  isbn={978-1-4503-5581-0},
  location={Marina Del Rey, CA, USA},
  pages={531--539},
  numpages={9},
  html={http://doi.acm.org/10.1145/3159652.3159683},
  doi={10.1145/3159652.3159683},
  acmid={3159683},
  publisher={ACM},
  address={New York, NY, USA},
  keywords={cox-proportional hazards model, email interaction data, enterprise email marketing, survival analysis, time-to-event prediction},
}

@article{chaudhry2018modeling,
  abbr={EDM},
  bibtex_show={true},
  title={Modeling Hint-Taking Behavior and Knowledge State of Students with Multi-Task Learning.},
  author={Chaudhry, Ritwick and Singh, Harvineet and Dogga, Pradeep and Saini, Shiv Kumar},
  journal={International Educational Data Mining Society},
  year={2018},
  pdf={https://educationaldatamining.org/files/conferences/EDM2018/papers/EDM2018_paper_100.pdf},
  publisher={ERIC}
}

@inproceedings{nambhi2019stuck,
  abbr={UMAP},
  bibtex_show={true},
  title={Stuck? No worries!: Task-aware Command Recommendation and Proactive Help for Analysts},
  author={Nambhi, Aadhavan M and Reddy, Bhanu Prakash and Agarwal, Aarsh Prakash and Verma, Gaurav and Singh, Harvineet and Burhanuddin, Iftikhar Ahamath},
  booktitle={ACM UMAP},
  html={https://arxiv.org/abs/1906.08973},
  year={2019}
}

@article{bora2015role,
  abbr={Springer Journal},
  bibtex_show={true},
  title={On the role of conductance, geography and topology in predicting hashtag virality},
  author={Bora, Siddharth and Singh, Harvineet and Sen, Anirban and Bagchi, Amitabha and Singla, Parag},
  journal={Social Network Analysis and Mining},
  volume={1},
  number={5},
  pages={1--15},
  year={2015}
}